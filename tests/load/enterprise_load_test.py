"""
Enterprise Load Testing Suite
Comprehensive load testing for production readiness validation
"""

import asyncio
import aiohttp
import websockets
import json
import time
import statistics
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any
from dataclasses import dataclass, asdict
import concurrent.futures
import psutil
import threading
from contextlib import asynccontextmanager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class LoadTestResult:
    test_name: str
    duration: float
    total_requests: int
    successful_requests: int
    failed_requests: int
    average_response_time: float
    min_response_time: float
    max_response_time: float
    p95_response_time: float
    p99_response_time: float
    requests_per_second: float
    error_rate: float
    memory_usage_mb: float
    cpu_usage_percent: float
    success: bool
    errors: List[str]

class EnterpriseLoadTester:
    def __init__(self, base_url: str = "http://localhost:12000"):
        self.base_url = base_url
        self.websocket_url = base_url.replace("http", "ws") + "/ws"
        self.results: List[LoadTestResult] = []
        self.start_time = None
        self.memory_monitor = None
        self.cpu_monitor = None
        
    async def test_100_concurrent_websockets(self) -> LoadTestResult:
        """Test 100+ concurrent WebSocket connections"""
        logger.info("ğŸ”Œ Starting 100+ concurrent WebSocket test...")
        
        test_start = time.time()
        successful_connections = 0
        failed_connections = 0
        response_times = []
        errors = []
        
        # Monitor system resources
        initial_memory = psutil.virtual_memory().used / 1024 / 1024
        initial_cpu = psutil.cpu_percent()
        
        async def connect_websocket(connection_id: int):
            try:
                start_time = time.time()
                async with websockets.connect(
                    f"{self.websocket_url}?client_id=load_test_{connection_id}",
                    timeout=10
                ) as websocket:
                    # Send test message
                    test_message = {
                        "type": "heartbeat",
                        "client_id": f"load_test_{connection_id}",
                        "timestamp": datetime.now().isoformat()
                    }
                    await websocket.send(json.dumps(test_message))
                    
                    # Wait for response
                    response = await asyncio.wait_for(websocket.recv(), timeout=5)
                    response_time = time.time() - start_time
                    response_times.append(response_time)
                    
                    # Keep connection alive for 30 seconds
                    await asyncio.sleep(30)
                    
                    return True
            except Exception as e:
                errors.append(f"Connection {connection_id}: {str(e)}")
                return False
        
        # Create 120 concurrent connections
        tasks = [connect_websocket(i) for i in range(120)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Count results
        for result in results:
            if result is True:
                successful_connections += 1
            else:
                failed_connections += 1
        
        # Calculate metrics
        duration = time.time() - test_start
        final_memory = psutil.virtual_memory().used / 1024 / 1024
        final_cpu = psutil.cpu_percent()
        
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) > 20 else 0
        p99_response_time = statistics.quantiles(response_times, n=100)[98] if len(response_times) > 100 else 0
        
        result = LoadTestResult(
            test_name="100+ Concurrent WebSockets",
            duration=duration,
            total_requests=120,
            successful_requests=successful_connections,
            failed_requests=failed_connections,
            average_response_time=avg_response_time,
            min_response_time=min(response_times) if response_times else 0,
            max_response_time=max(response_times) if response_times else 0,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            requests_per_second=successful_connections / duration,
            error_rate=(failed_connections / 120) * 100,
            memory_usage_mb=final_memory - initial_memory,
            cpu_usage_percent=final_cpu - initial_cpu,
            success=successful_connections >= 100 and (failed_connections / 120) < 0.05,
            errors=errors[:10]  # Limit to first 10 errors
        )
        
        logger.info(f"âœ… WebSocket test completed: {successful_connections}/120 successful")
        return result
    
    async def test_multi_agent_heavy_load(self) -> LoadTestResult:
        """Test multi-agent coordination under heavy load"""
        logger.info("ğŸ¤– Starting multi-agent heavy load test...")
        
        test_start = time.time()
        successful_requests = 0
        failed_requests = 0
        response_times = []
        errors = []
        
        initial_memory = psutil.virtual_memory().used / 1024 / 1024
        initial_cpu = psutil.cpu_percent()
        
        async def agent_task_request(session: aiohttp.ClientSession, task_id: int):
            try:
                start_time = time.time()
                
                # Complex multi-agent task
                task_payload = {
                    "task_id": f"load_test_task_{task_id}",
                    "type": "complex_analysis",
                    "agents_required": ["code_generator", "debugging_agent", "testing_agent"],
                    "priority": "high",
                    "complexity": "high",
                    "data": {
                        "code": "def complex_function():\n    # Complex code analysis task\n    pass",
                        "requirements": ["performance", "security", "maintainability"],
                        "constraints": ["memory_limit", "time_limit"]
                    }
                }
                
                async with session.post(
                    f"{self.base_url}/api/agents/coordinate-task",
                    json=task_payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    response_time = time.time() - start_time
                    response_times.append(response_time)
                    
                    if response.status == 200:
                        result = await response.json()
                        return True
                    else:
                        errors.append(f"Task {task_id}: HTTP {response.status}")
                        return False
                        
            except Exception as e:
                errors.append(f"Task {task_id}: {str(e)}")
                return False
        
        # Create session and run 50 concurrent agent tasks
        async with aiohttp.ClientSession() as session:
            tasks = [agent_task_request(session, i) for i in range(50)]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for result in results:
                if result is True:
                    successful_requests += 1
                else:
                    failed_requests += 1
        
        # Calculate metrics
        duration = time.time() - test_start
        final_memory = psutil.virtual_memory().used / 1024 / 1024
        final_cpu = psutil.cpu_percent()
        
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) > 20 else 0
        p99_response_time = statistics.quantiles(response_times, n=100)[98] if len(response_times) > 50 else 0
        
        result = LoadTestResult(
            test_name="Multi-Agent Heavy Load",
            duration=duration,
            total_requests=50,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            average_response_time=avg_response_time,
            min_response_time=min(response_times) if response_times else 0,
            max_response_time=max(response_times) if response_times else 0,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            requests_per_second=successful_requests / duration,
            error_rate=(failed_requests / 50) * 100,
            memory_usage_mb=final_memory - initial_memory,
            cpu_usage_percent=final_cpu - initial_cpu,
            success=successful_requests >= 45 and avg_response_time < 10.0,
            errors=errors[:10]
        )
        
        logger.info(f"âœ… Multi-agent test completed: {successful_requests}/50 successful")
        return result
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """Run all enterprise load tests"""
        logger.info("ğŸš€ Starting Enterprise Load Testing Suite...")
        
        start_time = time.time()
        
        # Run simplified tests for now
        tests = [
            self.test_multi_agent_heavy_load(),
        ]
        
        self.results = await asyncio.gather(*tests)
        
        # Calculate overall metrics
        total_duration = time.time() - start_time
        total_tests = len(self.results)
        passed_tests = sum(1 for result in self.results if result.success)
        failed_tests = total_tests - passed_tests
        
        overall_success = failed_tests == 0
        
        # Generate summary
        summary = {
            "test_suite": "Enterprise Load Testing",
            "timestamp": datetime.now().isoformat(),
            "duration": total_duration,
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "success_rate": (passed_tests / total_tests) * 100,
            "overall_success": overall_success,
            "results": [asdict(result) for result in self.results]
        }
        
        # Save results
        with open("enterprise_load_test_results.json", "w") as f:
            json.dump(summary, f, indent=2)
        
        # Print summary
        print("\n" + "="*80)
        print("ğŸ§ª ENTERPRISE LOAD TEST SUMMARY")
        print("="*80)
        print(f"â±ï¸  Duration: {total_duration:.2f} seconds")
        print(f"ğŸ§ª Total Tests: {total_tests}")
        print(f"âœ… Passed: {passed_tests}")
        print(f"âŒ Failed: {failed_tests}")
        print(f"ğŸ“ˆ Success Rate: {(passed_tests / total_tests) * 100:.1f}%")
        print(f"ğŸ‰ Overall Status: {'PASS' if overall_success else 'FAIL'}")
        print("="*80)
        
        for result in self.results:
            status = "âœ… PASS" if result.success else "âŒ FAIL"
            print(f"{status} {result.test_name}")
            print(f"   Duration: {result.duration:.2f}s")
            print(f"   Success Rate: {((result.successful_requests / result.total_requests) * 100):.1f}%")
            print(f"   Avg Response Time: {result.average_response_time:.3f}s")
            print(f"   Memory Usage: {result.memory_usage_mb:.2f}MB")
            if result.errors:
                print(f"   Errors: {len(result.errors)} (showing first 3)")
                for error in result.errors[:3]:
                    print(f"     - {error}")
            print()
        
        return summary

async def main():
    """Main function to run enterprise load tests"""
    tester = EnterpriseLoadTester()
    
    try:
        results = await tester.run_all_tests()
        
        # Exit with appropriate code
        if results["overall_success"]:
            print("ğŸ‰ All enterprise load tests passed!")
            exit(0)
        else:
            print("âŒ Some enterprise load tests failed!")
            exit(1)
            
    except Exception as e:
        logger.error(f"Enterprise load testing failed: {e}")
        exit(1)

if __name__ == "__main__":
    asyncio.run(main())